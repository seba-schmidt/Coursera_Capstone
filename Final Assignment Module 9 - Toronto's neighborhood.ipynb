{
    "cells": [
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Question 1"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "# I copied and pasted the table from Wikipedia into a CSV file and imported it into IBM Cloud Pak for Data.\n# Then I chose \"insert to code\" for the CSV file, which returned the following code (until df_data_1 = pd.read_csv(body))\n\nimport types\nimport pandas as pd\nfrom botocore.client import Config\nimport ibm_boto3\n\ndef __iter__(self): return 0\n\n# Message from IBM (pasted when calling the \"insert to code\" function. I replaced my credentials with \"CLIENT_ID\")\n# @hidden_cell\n# The following code accesses a file in your IBM Cloud Object Storage. It includes your credentials.\n# You might want to remove those credentials before you share the notebook.\nclient_980b1a452fbc47649c6801eeaa4c8f73 = ibm_boto3.client(service_name='s3',\n    ibm_api_key_id='-sr-LvN8cjMcjxJij-z8sHBcc0zK-6CY3Q2Kvo0xlfAy',\n    ibm_auth_endpoint=\"https://iam.cloud.ibm.com/oidc/token\",\n    config=Config(signature_version='oauth'),\n    endpoint_url='https://s3.eu-geo.objectstorage.service.networklayer.com')\n\nbody = client_980b1a452fbc47649c6801eeaa4c8f73.get_object(Bucket='datasciencefinalassignmentmodule8-donotdelete-pr-p7xhaymzrujbuv',Key='Neighborhoods.csv')['Body']\n# add missing __iter__ method, so pandas accepts body as file-like object\nif not hasattr(body, \"__iter__\"): body.__iter__ = types.MethodType( __iter__, body )\n\ndf_data_1 = pd.read_csv(body)\n\n# dropping null value columns to avoid errors \ndf_data_1.dropna(inplace = True) \n  \n# new data frame with split value columns \nnew = df_data_1[\"PostalCode;Borough;Neighbourhood\"].str.split(\";\", n = 2, expand = True) \n  \n# making separate first name column from new data frame \ndf_data_1[\"PostalCode\"]= new[0] \ndf_data_1[\"Borough\"]= new[1]\ndf_data_1[\"Neighborhood\"]= new[2]\n\n# Dropping old Name columns \ndf_data_1.drop(columns =[\"PostalCode;Borough;Neighbourhood\"], inplace = True)\n\n# Get names of indexes for which column Borough and Neighborhood are \"Not assigned\"\nindexNames = df_data_1[df_data_1['Borough'] == 'Not assigned' ].index\n\n# Delete these row indexes from dataFrame\ndf_data_1.drop(indexNames , inplace=True)\n\n# Reset the index and clean the data\ndf_data_1 = df_data_1.reset_index(drop=True)\ndf_data_1['Neighborhood'] = df_data_1['Neighborhood'].str.replace(r'\"', '')\ndf_data_1['Neighborhood'] = df_data_1['Neighborhood'].str.replace(r';', ',')\n\n# df display \ndf_data_1.head()",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "df_data_1.shape",
            "execution_count": 58,
            "outputs": [
                {
                    "output_type": "execute_result",
                    "execution_count": 58,
                    "data": {
                        "text/plain": "(103, 3)"
                    },
                    "metadata": {}
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Question 2"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "# Importing csv file and \"Insert to Code\", since geocoder did not work.\nimport types\nimport pandas as pd\nfrom botocore.client import Config\nimport ibm_boto3\n\ndef __iter__(self): return 0\n\n# Message from IBM (pasted when calling the \"insert to code\" function. I replaced my credentials with \"CLIENT_ID\")\n# @hidden_cell\n# The following code accesses a file in your IBM Cloud Object Storage. It includes your credentials.\n# You might want to remove those credentials before you share the notebook.\nclient_CLIENT_ID = ibm_boto3.client(service_name='s3',\n    ibm_api_key_id='-sr-LvN8cjMcjxJij-z8sHBcc0zK-6CY3Q2Kvo0xlfAy',\n    ibm_auth_endpoint=\"https://iam.cloud.ibm.com/oidc/token\",\n    config=Config(signature_version='oauth'),\n    endpoint_url='https://s3.eu-geo.objectstorage.service.networklayer.com')\n\nbody = client_CLIENT_ID.get_object(Bucket='datasciencefinalassignmentmodule8-donotdelete-pr-p7xhaymzrujbuv',Key='Geospatial_Coordinates.csv')['Body']\n# add missing __iter__ method, so pandas accepts body as file-like object\nif not hasattr(body, \"__iter__\"): body.__iter__ = types.MethodType( __iter__, body )\n\ndf_data_2 = pd.read_csv(body)\n\n# End of the automatically posted code from \"Insert to code\"\n\n# Merge the two tables on Postal Code\nNBH_latlon = pd.merge(left=df_data_1, right=df_data_2, left_on='PostalCode', right_on='Postal Code')\nNBH_latlon.drop(columns='Postal Code', inplace=True)\nNBH_latlon",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "",
            "execution_count": null,
            "outputs": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3.7",
            "language": "python"
        },
        "language_info": {
            "name": "python",
            "version": "3.7.9",
            "mimetype": "text/x-python",
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "pygments_lexer": "ipython3",
            "nbconvert_exporter": "python",
            "file_extension": ".py"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 1
}